{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8afe071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38a5c6fcde84707ab4eefc041e13a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marui\\anaconda3\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "StableAudioPipeline.__call__() got an unexpected keyword argument 'audio_length_in_s'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 17\u001b[0m\n\u001b[0;32m      7\u001b[0m pipe \u001b[38;5;241m=\u001b[39m StableAudioPipeline\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m      8\u001b[0m     model_id,\n\u001b[0;32m      9\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16\n\u001b[0;32m     10\u001b[0m )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misolated single bass drum note, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdry sound, clean attack, no vibrato, no reverb, no rhythm\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     15\u001b[0m )\n\u001b[1;32m---> 17\u001b[0m out \u001b[38;5;241m=\u001b[39m pipe(\n\u001b[0;32m     18\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[0;32m     19\u001b[0m     num_inference_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     20\u001b[0m     guidance_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6.0\u001b[39m,\n\u001b[0;32m     21\u001b[0m     audio_length_in_s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.0\u001b[39m\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     24\u001b[0m audio \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39maudios[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     25\u001b[0m sf\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstable_contrabass_note.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m, audio, \u001b[38;5;241m44100\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\marui\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: StableAudioPipeline.__call__() got an unexpected keyword argument 'audio_length_in_s'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import soundfile as sf\n",
    "from diffusers import StableAudioPipeline\n",
    "\n",
    "model_id = \"stabilityai/stable-audio-open-1.0\"\n",
    "\n",
    "pipe = StableAudioPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16\n",
    ").to(\"cuda\")\n",
    "\n",
    "prompt = (\n",
    "    \"isolated single bass drum note, \"\n",
    "    \"dry sound, clean attack, no vibrato, no reverb, no rhythm\"\n",
    ")\n",
    "\n",
    "negative_prompt = \"low quality, melody, rhythm, drums, reverb\"\n",
    "\n",
    "generator = torch.Generator(device).manual_seed(0) if device == \"cuda\" else None\n",
    "\n",
    "audio = pipe(\n",
    "    prompt,\n",
    "    negative_prompt=negative_prompt,\n",
    "    num_inference_steps=150,\n",
    "    guidance_scale=6.0,\n",
    "    audio_end_in_s=2.0,              # ✅ 길이 조절은 이걸로!\n",
    "    num_waveforms_per_prompt=3,      # 여러 개 뽑아서 고르기\n",
    "    generator=generator,\n",
    ").audios\n",
    "\n",
    "# audios는 보통 (batch, channels, samples) 형태라 저장용으로 transpose\n",
    "wav = audio[0].T.float().cpu().numpy()\n",
    "sf.write(\"stable_contrabass_note.wav\", wav, pipe.vae.sampling_rate)  # 보통 44100Hz :contentReference[oaicite:1]{index=1}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
